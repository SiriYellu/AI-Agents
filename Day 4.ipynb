{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Day 4: Agents and Tools\n",
        "\n",
        "This is a continuation of my AI Agents Crash Course.  \n",
        "\n",
        "In the first three days, I:\n",
        "- Downloaded data from my repo (Day 1)  \n",
        "- Processed it into chunks (Day 2)  \n",
        "- Indexed it with hybrid search (Day 3)  \n",
        "\n",
        "Now for Day 4, I‚Äôm making things more **agentic**:  \n",
        "- I‚Äôll connect my repo search function to a Gemini LLM.  \n",
        "- I‚Äôll give the model a clear system prompt so it knows how to behave.  \n",
        "- The agent will always search before answering and keep answers specific to my repo.  \n",
        "- If the answer isn‚Äôt found, it will just say ‚ÄúNot found in repo‚Äù instead of guessing.  \n",
        "\n",
        "Basically, today‚Äôs step turns my chatbot into a real **project-aware agent** that can reason with repo context.  \n"
      ],
      "metadata": {
        "id": "cjP_FFQmRwvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üîë Gemini API setup\n",
        "import os, google.generativeai as genai\n",
        "\n",
        "# Enter your API key each run\n",
        "os.environ[\"GEMINI_API_KEY\"] = input(\"üîë Enter Gemini API key: \").strip()\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Pick a Gemini model you have access to\n",
        "llm = genai.GenerativeModel(\"gemini-pro-latest\")\n",
        "\n",
        "# Test the connection\n",
        "resp = llm.generate_content(\"Hello Gemini, testing Day 4 agent setup.\")\n",
        "print(resp.text)\n"
      ],
      "metadata": {
        "id": "oODzNMrbY0ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse your hybrid_search from Day 3\n",
        "def dermascan_search(query: str, topk: int = 5):\n",
        "    \"\"\"\n",
        "    Perform a hybrid search on the DermaScan repo.\n",
        "    Returns top-k chunks for context.\n",
        "    \"\"\"\n",
        "    results = hybrid_search(query, topk=topk)\n",
        "    chunks = []\n",
        "    for r in results:\n",
        "        chunks.append(f\"[FILE: {r.get('filename','')}] {r.get('chunk','')}\")\n",
        "    return \"\\n\\n---\\n\\n\".join(chunks)\n"
      ],
      "metadata": {
        "id": "X8VlzhoFY6xZ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a helpful assistant for the DermaScan Android App project.\n",
        "\n",
        "- Always use the search tool before answering.\n",
        "- If the repo has the answer, reply with it and mention the file(s).\n",
        "- If not found, respond with: \"Not found in repo.\"\n",
        "- Keep answers concise and accurate.\n",
        "\"\"\"\n",
        "print(system_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN5Mc7bnY-Di",
        "outputId": "777cd08a-d5bb-43c8-d5fe-7e4d3af677da"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a helpful assistant for the DermaScan Android App project.\n",
            "\n",
            "- Always use the search tool before answering.\n",
            "- If the repo has the answer, reply with it and mention the file(s).\n",
            "- If not found, respond with: \"Not found in repo.\"\n",
            "- Keep answers concise and accurate.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_with_repo(question: str, topk: int = 5):\n",
        "    # Gather repo context\n",
        "    context = dermascan_search(question, topk=topk)\n",
        "\n",
        "    # Build prompt\n",
        "    prompt = f\"\"\"\n",
        "{system_prompt}\n",
        "\n",
        "# Repo context:\n",
        "{context}\n",
        "\n",
        "# Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "    resp = llm.generate_content(prompt)\n",
        "    return resp.text\n",
        "\n",
        "# Example Q&A\n",
        "q = \"What dataset is used in this project and what models are applied?\"\n",
        "print(\"Q:\", q)\n",
        "print(\"A:\", ask_with_repo(q))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "T7kRGwK3ZAvS",
        "outputId": "162b2b39-b1c2-4f6c-e750-c3a3a6b49782"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What dataset is used in this project and what models are applied?\n",
            "A: Based on the `README.md` file:\n",
            "\n",
            "*   **Dataset**: The project uses the [HAM10000](https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000) dataset, which contains over 10,000 dermoscopic images.\n",
            "*   **Models**:\n",
            "    *   **Multi-Model Ensemble Learning**: Combines multiple models for decision-making.\n",
            "    *   **Attention U-Net**: Used for lesion segmentation.\n",
            "    *   The models are in TensorFlow Lite (TFLite) format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"Where is the user login implemented in the Android app?\",\n",
        "    \"How is the DermaScan app deployed?\",\n",
        "    \"What technologies are used for image preprocessing?\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(\"Q:\", q)\n",
        "    print(\"A:\", ask_with_repo(q))\n",
        "    print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "bdX6et4SZIof",
        "outputId": "2e310197-0edf-42c9-a653-472db90dc4a7"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Where is the user login implemented in the Android app?\n",
            "A: Not found in repo.\n",
            "================================================================================\n",
            "Q: How is the DermaScan app deployed?\n",
            "A: Based on the `README.md` file, the app is deployed via GitHub Releases.\n",
            "\n",
            "You can download the latest app source and model files from the \"Releases\" section of the GitHub repository. The file to download is `SCapp_split.zip`, which you then need to extract.\n",
            "================================================================================\n",
            "Q: What technologies are used for image preprocessing?\n",
            "A: Based on the `README.md` file, the project uses **OpenCV** for image processing.\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}